# HW2-b4-03-24-2200



## 题目 3

> Rosenbrock函数是一个用来测试最优化算法性能的非凸函数，由Howard Harry Rosenbrock在1960年提出，也称为Rosenbrock山谷或Rosenbrock香蕉函数。其公式为：![img](data:image/png;base64,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)，很明显，其最小最为f(1, 1)=0，其三维图片如下：
>
> <img src="https://teachingoss.applysquare.com/2019/03/16/23/39/50/7810/185.png" alt="rosenbrock.png" style="zoom: 33%;" />
>
> 完善rosenbrock.py程序，采用梯度下降法计算Rosenbrock函数的最小值对应的x和y。补充"Your_code"处的代码，运行代码，将程序输出的最后5行截图，写出迭代完成后的iter_count值，函数值(精确到小数点后10位)和w值(精确到小数点后6位）。

### 程序输出最后五行（选中部分）

![image-20210323213333190](C:\Users\YuDongjun\AppData\Roaming\Typora\typora-user-images\image-20210323213333190.png)

#### `iter_count`值：5770

#### 函数值：0.0009998966

#### w值：(0.968405, 0.937680)

### 源代码

```python
import numpy as np
from sympy import *

Your_code = 'TBD'

def cal_f(x, y):
    # 计算Rosenbrock函数值
    res = np.square(1 - x) + 100 * np.square(y - np.square(x))
    return res


def cal_dx(xn, yn):
    # 计算x偏导数
    x, y = symbols('x y')
    # f = (1 - x) ** 2 + 100 * ((y - x ** 2) ** 2)
    f = np.square(1 - x) + 100 * (np.square(y - np.square(x)))
    # print(f)
    # print('diffx')
    # print(diff(f, x))
    f1 = diff(f, x).subs([(x, xn), (y, yn)])
    # f1 = -2 * (1 - xn) + 400 * xn * (yn - xn ** 2)
    return f1


def cal_dy(xn, yn):
    # 计算y偏导数
    x, y = symbols('x y')
    # f = (1 - x) ** 2 + 100 * ((y - x ** 2) ** 2)
    f = np.square(1 - x) + 100 * np.square(y - np.square(x))
    # print(f)
    # print('diffY')
    # print(diff(f, y))
    f1 = diff(f, y).subs([(x, xn), (y, yn)])
    # f1 = 200 * (yn - xn ** 2)
    return f1


def train_grad(max_iter=100000, step=0.001):  # 梯度下降迭代主函数

    w = np.zeros((2,), dtype=np.float32)  # 初始化求解数值从([0, 0])开始
    loss = 20  # 设置函数初值为20
    iter_count = 0

    while loss > 0.001 and iter_count < max_iter:
        err = np.zeros((2,), dtype=np.float32)

        # 计算x偏导数
        err[0] = cal_dx(w[0], w[1])

        # 计算y偏导数
        err[1] = cal_dy(w[0], w[1])

        for j in range(2):
            w[j] -= step * err[j]  # 梯度下降迭代

        loss = cal_f(w[0], w[1]) - 0  # 最小值为0

        # print('err' + str(err))
        # print('w' + str(w))
        print("iter_count: ", iter_count, "the loss:", cal_f(w[0], w[1]))  # 每次迭代输出迭代序号和当前函数值
        # print('---------------')
        iter_count += 1
    return w


if __name__ == '__main__':  # main主程序
    # 调用梯度下降迭代主函数
    w = train_grad(100000, 0.0001)
    # 显示w的值
    print(w)
```

